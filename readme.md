# Project Adam

Project Adam is a simulation designed to explore the principles of **emergent AI behavior**.
This README provides everything you need to **understand, install, run, and analyze** the project.

---

## üöÄ Quick Start

1. **Start the Psyche Service** (subconscious + imagination + reflection):

   ```bash
   python psyche_ollama.py
   ```

2. **Start Adam‚Äôs Mind**:

   Preferred entrypoint:

   ```bash
   python main.py
   ```

   Legacy script (still supported):

   ```bash
   python cognitive_loop_gui.py
   ```

   Headless mode (no GUI, loop + API only):

   ```bash
   python main.py --headless
   # optional: choose API port
   python main.py --headless --api-port 9090
   # optional: run a fixed number of cycles then exit
   python main.py --headless --cycles 10
   ```

3. **Watch the GUI**:

   * See impulses ‚Üí imagination ‚Üí reflection ‚Üí decision ‚Üí action.
   * Observe hunger/stress change over time.
   * Track storyline threads and insights.

---

## 1. Introduction

Project Adam is a Python-based simulation of an **Emergent Behavior Agent (EBA)** named Adam.
Unlike traditional scripted NPCs, Adam‚Äôs actions are **not hard-coded**. Instead, his behavior emerges from:

* **Psychological drives** (hunger, mood, curiosity, etc.)
* **Subconscious impulses** generated by an LLM (Ollama)
* **Conscious reasoning** that balances impulses, emotions, and goals
* **Persistent memory** stored in a vector database (Pinecone)
* **Environmental events** from a text-based world (TextWorld)

The goal is to model **free-will-like behavior**, where Adam develops habits and personality traits organically over time.

This project was born as an effort to represent the episode Hotel Reverie from Black Mirror series. In this episode, Brandy Friday, a top actor, agrees to star in a high-tech remake of the 1940s romance Hotel Reverie on the condition she plays a gender-swapped version of the male lead. Instead of a traditional shoot, her mind is placed into an AI-driven simulation of the film, where she interacts with digital replicas of the original characters in real time. When Brandy fails at a key piano scene, the story diverges from the original plot, and her attempts to repair it accidentally trigger Clara‚Äôs AI character to develop autonomy and consciousness.


---

## 2. Core Components

| Component                | File                    | Role                                                                             |
| ------------------------ | ----------------------- | -------------------------------------------------------------------------------- |
| **Text World**           | `text_world.py`         | Adam‚Äôs environment: a text-based apartment with rooms, objects, and events.      |
| **Psyche-LLM**           | `psyche_ollama.py`      | Adam‚Äôs subconscious: generates impulses, imagination, and reflection via Ollama. |
| **Memory**               | Pinecone DB             | Stores Adam‚Äôs memories as embeddings for long-term recall.                       |
| **Cognitive Loop + GUI** | `cognitive_loop_gui.py` | Adam‚Äôs conscious mind: runs the OODA cycle, integrates memory, manages the GUI.  |

---

## 3. System Architecture

Adam‚Äôs cognition flows between world, psyche, memory, and actions:

```mermaid
flowchart TD
    A[Text World<br/>`text_world.py`] -->|World State| B[Cognitive Loop<br/>`cognitive_loop_gui.py`]
    B -->|Prompts| C[Psyche-LLM<br/>`psyche_ollama.py`]
    C -->|Impulses / Reflection| B
    B -->|Embeddings| D[Pinecone DB<br/>Memory]
    D -->|Resonant Memories| B
```

---

## 4. Cognitive Loop (OODA Cycle)

Adam‚Äôs mind follows the **Observe ‚Üí Orient ‚Üí Decide ‚Üí Act** cycle:

```mermaid
flowchart LR
    O[Observe] --> R["Orient 
    (Memories + Impulses)"]
    R --> I["Imagine & Reflect
    (Simulated + LLM outcomes)"]
    I --> D["Decide
    (Final Action + Reasoning)"]
    D --> A["Act in TextWorld"]
    A --> M["Memory Formation\n(CSV + Pinecone)"]
    M --> O

```

---

## 5. Setup and Installation

### Prerequisites

* Python **3.10+**
* [Ollama](https://ollama.ai/) installed locally
* Pinecone account (optional but recommended)

### Install dependencies

```bash
pip install -r requirements.txt
```

Dependencies:

* `flask`, `requests`, `python-dotenv`
* `sentence-transformers`
* `pinecone-client`
* `tkinter` (bundled with Python on most platforms)

### Configure Environment

Copy the example env file and tweak values:

```bash
cp .env.example .env
```

Then edit `.env` to set pacing, logging, agent initialization, and optional vector memory.

The Flask state API exposes:

- `GET /get_state`: location + mood snapshot
- `GET /metrics`: cycle, mood, hunger, and current KPIs

### Configure Pinecone

1. Sign up at [pinecone.io](https://www.pinecone.io).

2. Create an index:

   | Setting        | Value                      |
   | -------------- | -------------------------- |
   | **Index Name** | `project-adam-memory-text` |
   | **Dimensions** | `384`                      |
   | **Metric**     | `cosine`                   |

3. Add credentials to `.env`:

   ```env
   PINECONE=<your_api_key>
   PINECONE_ENVIRONMENT=us-east-1
   ```

### Pull an Ollama model

```bash
ollama pull qwen3:1.7b
```

(You can also use `llama3`, `mistral`, etc.)

---

## 6. Running the Simulation

```bash
# Terminal 1: Start Psyche (LLM backend)
python psyche_ollama.py

# Terminal 2: Start Adam‚Äôs Mind + GUI (preferred)
python main.py

# Or headless
python main.py --headless

# Or legacy script
# python cognitive_loop_gui.py
```

---

## 6.1 Module Layout (refactor)

Recent refactor split major responsibilities into modules for clarity/testability:

- main.py: entrypoint wiring UI, loop, memory, psyche client, and API
- loop/cognitive_loop.py: OODA cognitive loop
- loop/insight_engine.py: KPI and insights
- services/memory_store.py: embeddings + Pinecone wrapper
- services/psyche_client.py: HTTP client to psyche service
- ui/psyche_monitor.py, ui/ui_bus.py, ui/text_redirector.py: Tkinter UI and helpers
- api.py: Flask state API factory
- config.py: env-backed configuration
- constants.py: shared constants (e.g., CSV LOG_HEADERS)

---

## 6.2 Configuration (env)

You can customize the loop and the agent via environment variables (in your shell or a `.env` file):

- Loop and logging
  - `CYCLE_SLEEP`: seconds between cycles (default: `5`)
  - `IMAGINE_TOP_K`: number of impulses to imagine per cycle (default: `3`)
  - `LOG_FILE`: path to CSV log (default: `adam_loop.log`)
  - `PSYCHE_LLM_API_URL`: psyche HTTP base URL (default: `http://127.0.0.1:5000/`)
  - `LOG_LEVEL`: Python logging level (default: `INFO`)
  - `PSYCHE_TIMEOUT`, `PSYCHE_RETRIES`, `PSYCHE_BACKOFF`: control HTTP client behavior to the psyche service
  - `MEMORY_UPSERT_BATCH`: buffer size for vector upserts to Pinecone (default: `5`)

- Agent initialization
  - Simple keys:
    - `AGENT_MOOD` (default: `neutral`)
    - `AGENT_LEVEL` (default: `0.1`)
    - `AGENT_CURIOSITY` (default: `0.8`)
    - `AGENT_BRAVERY` (default: `0.6`)
    - `AGENT_CAUTION` (default: `0.7`)
    - `AGENT_HUNGER` (default: `0.1`)
    - `AGENT_GOAL` (default: `Find the source of the strange noises in the house.`)
  - Full JSON override (replaces all above):

```bash
export AGENT_STATUS_JSON='{
  "emotional_state": {"mood": "anxious", "level": 0.4},
  "personality": {"curiosity": 0.7, "bravery": 0.4, "caution": 0.8},
  "needs": {"hunger": 0.15},
  "goal": "Calm the environment and rest."
}'
```

- Vector memory (optional; degrades gracefully if unset):
  - `SENTENCE_MODEL` (e.g., `all-MiniLM-L6-v2`)
  - `PINECONE` (API key)
  - `PINECONE_ENVIRONMENT`
  - `PINECONE_INDEX_NAME`

---

## 7. World Simulation

Adam lives in a **virtual apartment** simulated by `TextWorld`:

* **Rooms**: living room, kitchen, bedroom, office
* **Objects**: phone, door, window, TV, radio, fridge, bed, book, computer, plant
* **Actions**: `wait`, `go`, `examine`, `open`, `close`, `read`, `eat`, `answer`, `toggle`, `sleep`, `water`
* **Events**:

  * Random: phone ringing, door knocking, TV static, radio music, computer error
  * Time: day/night cycle every 10 ticks
* **Needs**:

  * `hunger` rises over time ‚Üí lowered by eating
  * `mood_intensity` rises with stress ‚Üí lowered by calming actions (sleep, read, answer phone)

---

## 8. GUI Overview

Running `cognitive_loop_gui.py` opens the **Psyche Monitor**:

* **Vitals Panel**

  * Mood label + progress bar
  * Hunger progress bar (color-coded)
* **Mind Tabs**

  * *Insights*: causal chain, badges (frustration, loops, avoidance), story cards, storyline threads
  * *Subconscious*: impulses + emotional shift JSON
  * *Imagination*: predicted vs simulated outcomes
  * *Decision*: final action + reasoning
* **Live Log**

  * Adam‚Äôs narration + world events
* **Storyline Threads**

  * Tracks progress per object (e.g. door storyline, phone storyline)

### GUI Controls

- Pause: stops the loop after the current cycle; UI remains interactive.
- Resume: restarts continuous cycling at the current ‚ÄúCycle sec‚Äù pacing.
- Step: runs exactly one full cycle (Observe ‚Üí Orient ‚Üí Imagine/Reflect ‚Üí Decide ‚Üí Act). If running, it marks ‚Äúpause after this cycle‚Äù.
- Clear Filter: clears the active storyline filter and restores full context in the panes.
- Save Snapshot: writes a JSON snapshot of the current cycle (agent status, KPIs, last hypothetical outcomes) to `snapshot_<timestamp>.json` in the CWD.
- Copy Metrics: copies the current KPIs JSON to the clipboard.
- Cycle sec: adjusts the delay between cycles (also affects stepping); lower is faster.
- Log: runtime logging level for the live console (DEBUG/INFO/WARNING/ERROR/CRITICAL).
- Font: scales the font size used in the JSON/log panes.
- Dark: toggles a dark color scheme for the text panes.
- Autoscroll: keeps the console pinned to the latest log entries when enabled.
- Simple mode: hides the raw JSON tabs to keep Insights front‚Äëand‚Äëcenter.

Tips
- Selecting a thread applies a target filter across Subconscious, Imagination, Decision, and the Insights cards. Use ‚ÄúClear Filter‚Äù to reset.
- In Insights, hover the timeline boxes for a quick tooltip; click to set the causal label. When filtered, a small ‚ÄúTarget trend‚Äù sparkline appears under the badges.

---

## 9. Logs and Memory

* **CSV log** (`adam_behavior_log.csv`):
  Records each cycle with fields:

  ```
  timestamp, cycle_num, agent_id, world_time, location, mood, mood_intensity,
  sensory_events, resonant_memories, impulses, chosen_action, action_result,
  imagined_outcomes, simulated_outcomes, emotional_delta, kpis, snapshot
  ```

* **Pinecone memory**:
  Stores vector embeddings of memories, enabling recall of ‚Äúresonant‚Äù past experiences.

---

# 10. Metrics and KPIs

Project Adam tracks several metrics to quantify Adam‚Äôs behavior:

| **Metric**        | **Formula / Source**                                                     | **Meaning**                                                                 |
|--------------------|--------------------------------------------------------------------------|-------------------------------------------------------------------------------|
| Frustration        | Failed actions √∑ total actions (last 10 cycles)                         | High = Adam is failing repeatedly, building stress                           |
| Conflict           | Suppressed strong impulses √∑ total high-urgency impulses                 | High = Adam ignores his strongest urges (internal conflict)                  |
| Novelty            | Unique triggers √∑ total triggers (last 10 cycles)                       | High = Adam experiences diverse stimuli, Low = repetition                     |
| Loop Score         | Longest streak of repeated failed (verb, target) actions, normalized     | High = Adam is stuck in a failure loop                                       |
| Goal Progress      | Heuristic: helpful verbs ~0.5‚Äì0.7, detours ~0.2, default ~0.3            | Higher = action aligns with long-term goal                                   |
| Emotional Delta    | JSON: {mood, level_delta, reason} from subconscious                      | Captures how impulses shift mood/stress each cycle                           |
| Snapshot           | JSON summary: triggers, impulses, chosen action, outcome, deltas, KPIs   | Provides structured per-cycle context                                        |
| Badges             | Derived flags (loop, frustration, avoidance)                            | Highlights key patterns: repeating loops, high stress, suppressed impulses    |


## 11. Typical Workflow

1. Start **Psyche** service.
2. Start **GUI + Loop**.
3. Observe Adam:

   * Impulses ‚Üí Imagination ‚Üí Reflection ‚Üí Decision ‚Üí Action
   * Hunger/stress bars change in real time
   * Insights show loops, frustration, or conflicts
   * CSV + Pinecone record memories for later analysis

---

## 12. Emergent Behaviors

* **Cognitive overload**
  Multiple impulses may overwhelm Adam, leading him to `wait`.

* **Wishful thinking loops**
  Adam may repeatedly attempt failed actions (e.g. opening a locked door).
  The reflection engine + loop-breaking hints reduce this.

* **Stress dynamics**
  Stress rises from repeated failures or unresolved stimuli (ringing phone, knocking door).
  Calming actions visibly reduce stress in the GUI.

* **Storyline progression**
  Threads track per-object attempts and outcomes ‚Üí e.g. ‚Äúdoor storyline: 2 fails, 1 success.‚Äù

---

## 13. Analyzing Behavior

Analyze CSV logs in Jupyter/Colab:

* **KPIs**: frustration, conflict, novelty, loop score, goal progress
* **Event chains**: visualize causal lines (trigger ‚Üí impulse ‚Üí action ‚Üí result)
* **Memory recall**: inspect which past events influenced current choices

### Notebook Workflow (adam_log_analysis.ipynb)

- Open `adam_log_analysis.ipynb` and run the first cells. It uses `analysis_utils.py` for parsing and plots.
- Default CSV path resolves from `LOG_FILE` in `.env` (written by the GUI) or falls back to `adam_behavior_log.csv`.

Minimal usage inside the notebook:

```python
from analysis_utils import prepare_dataframe, experiment_dashboard, plot_kpi_overlay, kpi_correlation_heatmap

df = prepare_dataframe()  # uses LOG_FILE or default
experiment_dashboard(df, save=True)  # saves figures/ and shows rolling trends

# Overlays by experiment/agent
plot_kpi_overlay(df, metric="frustration", by="experiment_tag", rolling=5)
plot_kpi_overlay(df, metric="mismatch_rate", by="agent_id", rolling=5)

# KPI correlations
kpi_correlation_heatmap(df)
```

If you edit `analysis_utils.py`, reload it in-place:

```python
import importlib, analysis_utils as au
au = importlib.reload(au)
```

---

## 14. Extending the Project

Ideas for expansion:

* Add new **rooms/objects** (balcony, bathroom, etc.)
* Extend **actions** (cook, write, repair, play music)
* Add **personality sliders** (curiosity, bravery, caution) ‚Üí bias impulses
* Simulate **multi-agent interactions** (Adam + another character)
* Experiment with different Ollama models for subconscious & reflection

---

## ‚úÖ Summary

Project Adam is a sandbox for experimenting with **emergent AI behavior**:

* A **world** that generates stimuli
* A **psyche** that produces impulses and imagination
* A **cognitive loop** that reasons, decides, and acts
* A **memory system** that grows with experience

Together, these simulate an agent who doesn‚Äôt just follow a script ‚Äî but **develops patterns, frustrations, and habits** in a believable way.

---
